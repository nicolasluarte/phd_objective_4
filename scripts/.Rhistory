) %>%
ungroup() %>%
group_by(ID) %>%
arrange(fecha, .by_group = TRUE) %>%
mutate(rel_date=replace_na(as.numeric(fecha-head(fecha,n=1)),0)) %>%
filter(new_event==1) %>%
mutate(
actions = sensor+1,
rewards = new_reward
) %>%
select(ID, rel_date, actions, rewards, treatment) %>%
group_by(ID, treatment) %>%
group_split()
write_csv(x = ed_choice %>% bind_rows(), "../datasets/individual_choice_data.csv")
# model fit ----
plan(multisession, workers = 12)
model_fits <- 1:1000 %>%
future_map_dfr(., function(iteration){
it <- map_dfr(ed_choice, function(X){
dat_sim <- X
lower_bounds <- c(alpha = 0.001, tau = 0.001) # Use small positive values
upper_bounds <- c(alpha = 1, tau = 5)      # Reasonable upper bounds
start_par <- c(
runif(1, min = lower_bounds[1], max = upper_bounds[1]),
runif(1, min = lower_bounds[2], max = upper_bounds[2])
)
param_optim <- optim(
par = start_par,
fn = likelihood_function,
method = "L-BFGS-B",
lower = lower_bounds,
upper = upper_bounds,
actions = dat_sim$actions,
rewards = dat_sim$rewards
)
optim_res <- param_optim$par
return(tibble(
opt_alpha = optim_res[1],
opt_tau = optim_res[2],
likelihood = param_optim$value,
iteration = iteration,
ID = dat_sim$ID[1],
treatment = dat_sim$treatment[1],
rel_date = dat_sim$rel_date[1]
))
})
return(it)
}, .options = furrr_options(seed = 6911))
write_rds(model_fits, "../datasets/RL_model_fits.rds")
optimal_mdl_fit <- read_rds("../datasets/RL_model_fits.rds") %>%
filter(likelihood != 0) %>%
group_by(ID, rel_date) %>%
slice(which.min(likelihood)) %>%
mutate(
drug = str_extract(treatment, "veh|tcs"),
entropy_level = str_extract(treatment, "[a-z]+_[a-z]+")
)
optimal_mdl_fit
# check for exact 0s and 1s in alpha
sum(optimal_mdl_fit$opt_alpha == 0)
sum(optimal_mdl_fit$opt_alpha == 1)
# the same for tau after transformation to 0 and 1
sum(optimal_mdl_fit$opt_tau/5 == 0)
sum(optimal_mdl_fit$opt_tau/5 == 1)
rl_mdl_data <- optimal_mdl_fit %>%
ungroup() %>%
mutate(
learning_rate = (opt_alpha * (n() - 1) + 0.5) / n(),
temperature = ((opt_tau/5)* (n() - 1) + 0.5) / n()
) %>%
group_by(ID) %>%
arrange(treatment, rel_date, .by_group = TRUE)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (drug | ID),
family = glmmTMB::beta_family(link="logit"),
control = glmmTMB::glmmTMBControl(optimizer = optim,
optArgs = list(method = "BFGS"),
profile = TRUE)
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
optimal_mdl_fit <- read_rds("../datasets/RL_model_fits.rds") %>%
group_by(ID, rel_date) %>%
slice(which.min(likelihood)) %>%
mutate(
drug = str_extract(treatment, "veh|tcs"),
entropy_level = str_extract(treatment, "[a-z]+_[a-z]+")
)
optimal_mdl_fit
# check for exact 0s and 1s in alpha
sum(optimal_mdl_fit$opt_alpha == 0)
sum(optimal_mdl_fit$opt_alpha == 1)
# the same for tau after transformation to 0 and 1
sum(optimal_mdl_fit$opt_tau/5 == 0)
sum(optimal_mdl_fit$opt_tau/5 == 1)
rl_mdl_data <- optimal_mdl_fit %>%
ungroup() %>%
mutate(
learning_rate = (opt_alpha * (n() - 1) + 0.5) / n(),
temperature = ((opt_tau/5)* (n() - 1) + 0.5) / n()
) %>%
group_by(ID) %>%
arrange(treatment, rel_date, .by_group = TRUE)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (drug | ID),
family = glmmTMB::beta_family(link="logit"),
control = glmmTMB::glmmTMBControl(optimizer = optim,
optArgs = list(method = "BFGS"),
profile = TRUE)
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
ed_choice <- ed %>%
group_by(ID, fecha) %>%
arrange(tiempo, .by_group = TRUE) %>%
ungroup() %>%
mutate(
rel_date = replace_na(as.numeric(fecha-lag(fecha, default = NA)), 0),
treatment = interaction(estimulo_spout_1, estimulo_spout_2, droga),
treatment = case_when(
treatment == "cond10perc100prob.cond10perc100prob.na_na_na_na" ~ "baseline",
treatment == "cond100prob.cond100prob.veh_na_na_na" ~ "low_entropy_veh",
treatment == "cond100prob.cond100prob.tcs_na_na_na" ~ "low_entropy_tcs",
treatment == "cond50prob.cond100prob.veh_na_na_na" ~ "mid_entropy_veh",
treatment == "cond50prob.cond100prob.tcs_na_na_na" ~ "mid_entropy_tcs",
treatment == "cond100prob.cond50prob.veh_na_na_na" ~ "mid_entropy_veh",
treatment == "cond100prob.cond50prob.tcs_na_na_na" ~ "mid_entropy_tcs",
treatment == "cond25prob.cond50prob.veh_na_na_na" ~ "high_entropy_veh",
treatment == "cond25prob.cond50prob.tcs_na_na_na" ~ "high_entropy_tcs",
treatment == "cond50prob.cond25prob.veh_na_na_na" ~ "high_entropy_veh",
treatment == "cond50prob.cond25prob.tcs_na_na_na" ~ "high_entropy_tcs",
TRUE ~ "ERROR"
)
) %>%
group_by(ID, fecha, sensor) %>%
filter(actividad != -1, treatment != "baseline") %>%
mutate(
exito = if_else(treatment=="low_entropy_tcs"|treatment=="low_entropy_veh", evento, exito),
new_event = replace_na(if_else(evento!=lag(evento), 1, 0), 1),
new_reward = replace_na(if_else(exito!=lag(exito), 1, 0), 1)
) %>%
ungroup() %>%
group_by(ID, fecha, sensor, evento) %>%
mutate(
lick_reward = if_else(max(new_reward)==1, 1, 0)
) %>%
ungroup() %>%
group_by(ID) %>%
arrange(fecha, .by_group = TRUE) %>%
mutate(rel_date=replace_na(as.numeric(fecha-head(fecha,n=1)),0)) %>%
#filter(new_event==1) %>%
mutate(
actions = sensor+1,
rewards = lick_reward
) %>%
select(ID, rel_date, actions, rewards, treatment) %>%
group_by(ID, treatment) %>%
group_split()
write_csv(x = ed_choice %>% bind_rows(), "../datasets/individual_choice_data.csv")
# model fit ----
plan(multisession, workers = 12)
model_fits <- 1:100 %>%
future_map_dfr(., function(iteration){
it <- map_dfr(ed_choice, function(X){
dat_sim <- X
lower_bounds <- c(alpha = 0.001, tau = 0.001) # Use small positive values
upper_bounds <- c(alpha = 1, tau = 5)      # Reasonable upper bounds
start_par <- c(
runif(1, min = lower_bounds[1], max = upper_bounds[1]),
runif(1, min = lower_bounds[2], max = upper_bounds[2])
)
param_optim <- optim(
par = start_par,
fn = likelihood_function,
method = "L-BFGS-B",
lower = lower_bounds,
upper = upper_bounds,
actions = dat_sim$actions,
rewards = dat_sim$rewards
)
optim_res <- param_optim$par
return(tibble(
opt_alpha = optim_res[1],
opt_tau = optim_res[2],
likelihood = param_optim$value,
iteration = iteration,
ID = dat_sim$ID[1],
treatment = dat_sim$treatment[1],
rel_date = dat_sim$rel_date[1]
))
})
return(it)
}, .options = furrr_options(seed = 6911))
write_rds(model_fits, "../datasets/RL_model_fits.rds")
optimal_mdl_fit <- read_rds("../datasets/RL_model_fits.rds") %>%
group_by(ID, rel_date) %>%
slice(which.min(likelihood)) %>%
mutate(
drug = str_extract(treatment, "veh|tcs"),
entropy_level = str_extract(treatment, "[a-z]+_[a-z]+")
)
optimal_mdl_fit
# check for exact 0s and 1s in alpha
sum(optimal_mdl_fit$opt_alpha == 0)
sum(optimal_mdl_fit$opt_alpha == 1)
# the same for tau after transformation to 0 and 1
sum(optimal_mdl_fit$opt_tau/5 == 0)
sum(optimal_mdl_fit$opt_tau/5 == 1)
rl_mdl_data <- optimal_mdl_fit %>%
ungroup() %>%
mutate(
learning_rate = (opt_alpha * (n() - 1) + 0.5) / n(),
temperature = ((opt_tau/5)* (n() - 1) + 0.5) / n()
) %>%
group_by(ID) %>%
arrange(treatment, rel_date, .by_group = TRUE)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (drug | ID),
family = glmmTMB::beta_family(link="logit"),
control = glmmTMB::glmmTMBControl(optimizer = optim,
optArgs = list(method = "BFGS"),
profile = TRUE)
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
optimal_mdl_fit
rl_mdl_data
rl_mdl_data$temperature %>% summary
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "response"
)
temperature_mdl_emm
x$rewards %>% unique
View(x)
# same idea for the learning rate
lrate_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
learning_rate ~ drug * entropy_level + (1|ID),
family = glmmTMB::beta_family(link="logit")
)
summary(lrate_mdl)
lrate_mdl_emm <- emmeans::emmeans(
lrate_mdl,
revpairwise ~ exp_group | exp_phase,
type = "response"
)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "response"
)
temperature_mdl_emm
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
# empirical data ----
ed <- read_csv("../datasets/lickometer_complete.csv")
ed_choice <- ed %>%
group_by(ID, fecha) %>%
arrange(tiempo, .by_group = TRUE) %>%
ungroup() %>%
mutate(
rel_date = replace_na(as.numeric(fecha-lag(fecha, default = NA)), 0),
treatment = interaction(estimulo_spout_1, estimulo_spout_2, droga),
treatment = case_when(
treatment == "cond10perc100prob.cond10perc100prob.na_na_na_na" ~ "baseline",
treatment == "cond100prob.cond100prob.veh_na_na_na" ~ "low_entropy_veh",
treatment == "cond100prob.cond100prob.tcs_na_na_na" ~ "low_entropy_tcs",
treatment == "cond50prob.cond100prob.veh_na_na_na" ~ "mid_entropy_veh",
treatment == "cond50prob.cond100prob.tcs_na_na_na" ~ "mid_entropy_tcs",
treatment == "cond100prob.cond50prob.veh_na_na_na" ~ "mid_entropy_veh",
treatment == "cond100prob.cond50prob.tcs_na_na_na" ~ "mid_entropy_tcs",
treatment == "cond25prob.cond50prob.veh_na_na_na" ~ "high_entropy_veh",
treatment == "cond25prob.cond50prob.tcs_na_na_na" ~ "high_entropy_tcs",
treatment == "cond50prob.cond25prob.veh_na_na_na" ~ "high_entropy_veh",
treatment == "cond50prob.cond25prob.tcs_na_na_na" ~ "high_entropy_tcs",
TRUE ~ "ERROR"
)
) %>%
group_by(ID, fecha, sensor) %>%
filter(actividad != -1, treatment != "baseline") %>%
mutate(
exito = if_else(treatment=="low_entropy_tcs"|treatment=="low_entropy_veh", evento, exito),
new_event = replace_na(if_else(evento!=lag(evento), 1, 0), 0),
new_reward = replace_na(if_else(exito!=lag(exito), 1, 0), 0)
) %>%
ungroup() %>%
group_by(ID, fecha, sensor, evento) %>%
mutate(
lick_rewarded = if_else(max(new_reward)==1, 1, 0)
) %>%
ungroup() %>%
group_by(ID) %>%
arrange(fecha, .by_group = TRUE) %>%
mutate(rel_date=replace_na(as.numeric(fecha-head(fecha,n=1)),0)) %>%
filter(new_event==1) %>%
mutate(
actions = sensor+1,
rewards = new_reward
) %>%
select(ID, rel_date, actions, rewards, treatment) %>%
group_by(ID, treatment) %>%
group_split()
write_csv(x = ed_choice %>% bind_rows(), "../datasets/individual_choice_data.csv")
# model fit ----
plan(multisession, workers = 12)
model_fits <- 1:10000 %>%
future_map_dfr(., function(iteration){
it <- map_dfr(ed_choice, function(X){
dat_sim <- X
lower_bounds <- c(alpha = 0.001, tau = 0.001) # Use small positive values
upper_bounds <- c(alpha = 1, tau = 5)      # Reasonable upper bounds
start_par <- c(
runif(1, min = lower_bounds[1], max = upper_bounds[1]),
runif(1, min = lower_bounds[2], max = upper_bounds[2])
)
param_optim <- optim(
par = start_par,
fn = likelihood_function,
method = "L-BFGS-B",
lower = lower_bounds,
upper = upper_bounds,
actions = dat_sim$actions,
rewards = dat_sim$rewards
)
optim_res <- param_optim$par
return(tibble(
opt_alpha = optim_res[1],
opt_tau = optim_res[2],
likelihood = param_optim$value,
iteration = iteration,
ID = dat_sim$ID[1],
treatment = dat_sim$treatment[1],
rel_date = dat_sim$rel_date[1]
))
})
return(it)
}, .options = furrr_options(seed = 6911))
write_rds(model_fits, "../datasets/RL_model_fits.rds")
optimal_mdl_fit <- read_rds("../datasets/RL_model_fits.rds") %>%
group_by(ID, rel_date) %>%
slice(which.min(likelihood)) %>%
mutate(
drug = str_extract(treatment, "veh|tcs"),
entropy_level = str_extract(treatment, "[a-z]+_[a-z]+")
)
optimal_mdl_fit
# check for exact 0s and 1s in alpha
sum(optimal_mdl_fit$opt_alpha == 0)
sum(optimal_mdl_fit$opt_alpha == 1)
# the same for tau after transformation to 0 and 1
sum(optimal_mdl_fit$opt_tau/5 == 0)
sum(optimal_mdl_fit$opt_tau/5 == 1)
rl_mdl_data <- optimal_mdl_fit %>%
ungroup() %>%
mutate(
learning_rate = (opt_alpha * (n() - 1) + 0.5) / n(),
temperature = ((opt_tau/5)* (n() - 1) + 0.5) / n()
) %>%
group_by(ID) %>%
arrange(treatment, rel_date, .by_group = TRUE)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
rl_mdl_data
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + learning_rate + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level * learning_rate + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 + temperature | ID),
family = glmmTMB::beta_family(link="logit")
)
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 + drug | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
# used beta to inform the model of hard boundaries impose in the
# optimization procedure
temperature_mdl <- glmmTMB::glmmTMB(
data = rl_mdl_data,
temperature ~ drug * entropy_level + (1 + drug + entropy_level | ID),
family = glmmTMB::beta_family(link="logit")
)
summary(temperature_mdl)
temperature_mdl_emm <- emmeans::emmeans(
temperature_mdl,
revpairwise ~ drug | entropy_level,
type = "link"
)
temperature_mdl_emm
